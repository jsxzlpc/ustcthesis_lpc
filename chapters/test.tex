
\chapter{多渠道广告预算分配算法SVR+Q+MCKP}


\subsection{研究动机}



% 比如：文献\citep{pednault2002sequential}将与顾客的交互营销行为建模为一个马尔可夫过程，然后提出一种批处理的强化学习算法，进行营销策略的学习。文献\citep{archak2010budget}在MDP框架中提出了一个在线广告资金分配的贪婪算法，文献\citep{boutilier2016budget}通过使用多MDP来代表不同类型的顾客，然后使用线性规划的方法，解决资金的分配问题。但是，
随着强化学习的发展，越来越多的学者和企业开始采用强化学习思想解决营销资金的优化问题，但是，大多数工作都是针对单一市场渠道进行优化的\citep{zhang2017multi}，他们的解决方法主要是将客户和渠道的交互数据模拟成一个马尔可夫链，然后使用强化学习求解方法进行策略的学习\citep{,pednault2002sequential,archak2010budget,boutilier2016budget}。但是，这些解决方法都会用到用户的个人信息和交互数据，而在我们的场景中，只有渠道产生的投放效果数据，不存在顾客的数据，因此和我们要研究的多渠道的应用背景不符合。

据调研所知，和本文应用背景相关的文献有两篇，在文献\citep{yang2012budget}中，作者针对多渠道搜索广告竞价问题，首次提出一个分层预算分配框架，包括系统、广告和关键词三层，通过联动机制可以实现这三次预算的自动调整，以最大化长期收益，但是文章只在投放机制和框架的层面进行详细地介绍，并没有对分配策略展开深入的研究。在文献\citep{zhang2017multi}中，作者使用一种启发的二分搜索算法来从投放数据中寻找每个渠道最优的投放花费，并结合MCKP问题，来解决资金的分配问题，但是作者并没有考虑到长期利润最大化的问题。

综合考虑以上相关工作，本文提出一个解决多渠道广告资金分配的研究方案。将文献\citep{pednault2002sequential,archak2010budget,boutilier2016budget}中使用马尔科夫决策过程针对单渠道中的用户建模改为对多渠道本身进行建模，并利用Q-learning算法求出渠道的价值函数，然后通过文献\citep{zhang2017multi}中的MCKP方法来解决最终的资金分配优化问题。但是，这种解决方案仍然面临以下问题：

% 综合考虑以上文献，我们从解决单渠道的资金优化问题出发，将文献\citep{pednault2002sequential}中使用马尔科夫决策过程对用户建模改为对渠道进行建模，然后通过对多渠道广告投放中存在的问题进行分析，进而修改强化学习的奖赏函数来更好的表达渠道的价值函数，最后结合各渠道的价值函数并借助MCKP来解决多渠道的资金分配问题。

首先，对于大部分企业来说，广告投放是以天为单位进行的，所以投放数据量比较少，这会影响模型的训练和学习。另外，因为在广告投放的过程中，因为同一渠道上存在可变时间间隔的问题，会对值函数的学习造成一定的影响；而且，不同渠道间的广告投放效果也会相互影响，如果单单只考虑本渠道投放效果的期望回报，值函数的学习也是不准确的。

本章主要从以上两个方面进行改进。针对第一个问题，利用基于核函数的非参数化函数逼近方法解决小样本下的值函数逼近问题，然后借助文献\citep{pednault2002sequential}中的提出的批学习Q-learning离线学习方法进行学习，最后借助MCKP来解决资金的分配优化问题，形成一个初步的SVR+Q+MCKP算法。
针对第一个问题，从广告渠道的时空影响方面出发，分别提出对应的解决方法，形成最终的SVR+Q+MCKP算法。其中，时间方面，主要考虑单渠道自身的可变长时间间隔问题，空间方面，主要考虑渠道间的广告效果影响问题。