%!TEX root =  ../main.tex

\begin{abstract}
  强化学习是机器学习的重要组成部分，主要用于解决序贯决策问题。它通过智能体Agent不断地与环境进行交互，并从环境反馈的延迟回报中学习状态与行为之间的映射关系，以使得回报达到最大化。近年来，因为AlphaGo的成功，强化学习得到了空前的关注，目前主要应用于机器人、游戏等领域，并都取得了令人振奋的表现。但是，针对其它领域的研究和应用则相对甚少。另一方面，随着信息化和智能化的快速发展，越来越多的企业希望借助人工智能的力量辅助商业决策。其中，客户关系管理CRM就是通过各种技术改善企业和客户之间在销售、营销和服务上的业务关系，从而提高企业长期收益的方法，这与强化学习累计奖赏最大化的目的不谋而合，因此强化学习技术应用在CRM领域有着天然的优势。

  本文首先针对强化学习在应用中出现的环境不可完全观测性、收敛速度慢等问题，提出了相应的改进模型，并且将改进的模型分别应用到CRM领域中客户生命价值LTV最大化问题以及多渠道广告投放资金分配问题。主要研究内容包括以下三个部分：

  （1）针对部分可观测的环境，提出了基于RNN的深度强化学习混合模型，并使用该模型解决客户生命价值最大化的问题。该混合模型由两个网络构成，其中通过RNN网络从监督数据中学习到环境隐状态的表示后，再将隐状态作为DQN网络的输入，共同地优化控制以使得长期收益最大化。与其它深度强化学习相比，该模型没有直接将观测的环境状态作为强化学习的输入，而是将预测的隐状态作为输入。通过这种改进的网络结构可以在不需要借助领域知识的情况下，提高值函数的学习精度和速度。最后将该混合模型应用于邮件定向推广中的客户生命价值最大化问题。

  （2）针对在非参数逼近时，算法收敛速度慢，逼近精度低等问题，提出了基于RBF-SVR的分片逼近强化学习模型，并将其应用资金分配问题。其中，利用RBF-SVR可以将强化学习中的值函数逼近转化为高维特征空间中的线性回归问题，从而可以提高算法的收敛速度；将行为空间进行离散化后，提出分片学习的强化学习思想，提高了模型逼近的精度。最后，将该模型和多选择背包问题结合，应用于多渠道广告投放资金分配问题上，并且针对该应用场景数据量少等特点，提出了一种基于二分查找的花费空间离散化方法、改进的值函数求解方法以及改进的行为策略探索的方式。

  （3）实验验证阶段，构建了邮件定向推广的仿真器。实验表明，基于RNN的深度强化学习混合模型具有出色的性能；另外，基于RBF-SVR的分片逼近强化学习模型在真实的广告投放中取得了较好的成绩，而且，通过构建了仿真环境，也侧面验证了模型的有效性。


  \keywords{强化学习；深度学习；函数逼近；客户生命价值；多渠道广告投放学位论文}
\end{abstract}

\begin{enabstract}
  This is a sample document of USTC thesis \LaTeX{} template for bachelor,
  master and doctor. The template is created by zepinglee and seisman, which
  orignate from the template created by ywg. The template meets the
  equirements of USTC theiss writing standards.

  This document will show the usage of basic commands provided by \LaTeX{} and
  some features provided by the template. For more information, please refer to
  the template document ustcthesis.pdf.

  \enkeywords{University of Science and Technology of China (USTC); Thesis;
  \LaTeX{} Template; Bachelor; Master; PhD}
\end{enabstract}
